{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebcccc0",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# <load_csv_pandas>\n",
    "# /// script\n",
    "# requires-python = \">=3.11\"\n",
    "# dependencies = [\n",
    "#     \"pandas\",\n",
    "# ]\n",
    "# ///"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01428aaf",
   "metadata": {},
   "source": [
    "### CSV Loading with Pandas\n",
    "This example demonstrates how to load a CSV file, with self-healing data generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831e2faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pathlib\n",
    "import urllib.request\n",
    "\n",
    "# Standard \"Wrangling Hero\" dataset: Palmer Penguins\n",
    "CSV_URL = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/penguins.csv\"\n",
    "DATA_PATH = pathlib.Path(\"penguins.csv\")\n",
    "\n",
    "# Self-healing: Download if missing\n",
    "if not DATA_PATH.exists():\n",
    "    urllib.request.urlretrieve(CSV_URL, DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb14651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic CSV loading\n",
    "# We use the standardized penguins.csv dataset\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(f\"Pandas loaded {len(df)} rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# With options (Selective columns and handling NaNs)\n",
    "df = pd.read_csv(\n",
    "    DATA_PATH,\n",
    "    usecols=[\"species\", \"island\", \"bill_length_mm\"],\n",
    "    na_values=[\"NA\"],\n",
    ")\n",
    "print(\"\\nSelective columns:\")\n",
    "print(df.head())\n",
    "# </load_csv_pandas>"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
