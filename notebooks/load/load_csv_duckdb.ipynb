{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500d3eac",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# <load_csv_duckdb>\n",
    "# /// script\n",
    "# requires-python = \">=3.11\"\n",
    "# dependencies = [\n",
    "#     \"duckdb\",\n",
    "#     \"pandas\",\n",
    "# ]\n",
    "# ///"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a14e3e3",
   "metadata": {},
   "source": [
    "### CSV Loading with DuckDB\n",
    "Using SQL to query CSV files directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c014b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pathlib\n",
    "import urllib.request\n",
    "\n",
    "# Standard \"Wrangling Hero\" dataset: Palmer Penguins\n",
    "CSV_URL = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/penguins.csv\"\n",
    "DATA_PATH = pathlib.Path(\"penguins.csv\")\n",
    "\n",
    "# Self-healing: Download if missing\n",
    "if not DATA_PATH.exists():\n",
    "    urllib.request.urlretrieve(CSV_URL, DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061f26aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic CSV loading via SQL\n",
    "# DuckDB can query CSV files directly\n",
    "print(\"DuckDB querying penguins via SQL:\")\n",
    "duckdb.sql(f\"SELECT * FROM '{DATA_PATH}' LIMIT 5\").show()\n",
    "# </load_csv_duckdb>"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
